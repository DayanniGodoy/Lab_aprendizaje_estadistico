{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e2753e4-9dc7-41d7-b080-d1abfbb16b28",
   "metadata": {},
   "source": [
    "# Laboratorio de regresión - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c396ea70-b88c-4346-a14f-4aa7ca2e1b00",
   "metadata": {},
   "source": [
    "|                |   |\r\n",
    ":----------------|---|\r\n",
    "| **Nombre**     Dayanni Godoy Rosales|   |\r\n",
    "| **Fecha**     09/09/2024 |   |\r\n",
    "| **Expediente*749206* |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77def53e-10bf-474e-acdf-728e07bef102",
   "metadata": {},
   "source": [
    "## Modelos penalizados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bb791d-1843-4b4d-bd8b-69e6419511e8",
   "metadata": {},
   "source": [
    "Hasta ahora la función de costo que usamos para decidir qué tan bueno es nuestro modelo al momento de ajustar es:\n",
    "\n",
    "$$ \\text{RSS} = \\sum_{i=1}^n e_i^2 = \\sum_{i=1}^n (y_i - \\hat{y_i})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b5e6b-abe9-4b75-b045-e4444de4fc35",
   "metadata": {},
   "source": [
    "Dado que los errores obtenidos son una combinación de sesgo y varianza, puede ser que se sesgue un parámetro para minimizar el error. Esto significa que el modelo puede decidir que la salida no sea una combinación de los factores, sino una fuerte predilección sobre uno de los factores solamente. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84901f9e-5551-455a-a70c-c7e39d9e55ae",
   "metadata": {},
   "source": [
    "E.g. se quiere ajustar un modelo\n",
    "\n",
    "$$ \\hat{z} = \\hat{\\beta_0} + \\hat{\\beta_1} x + \\hat{\\beta_2} y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f473fc-6364-4b15-9bd4-f21a94cae151",
   "metadata": {},
   "source": [
    "Se ajusta el modelo y se decide que la mejor decisión es $\\hat{\\beta_1} = 10000$ y $\\hat{\\beta_2}=50$. Considera limitaciones de problemas reales:\n",
    "- Quizás los parámetros son ajustes de maquinaria que se deben realizar para conseguir el mejor producto posible, y que $10000$ sea imposible de asignar.\n",
    "- Quizás los datos actuales están sesgados y sólo hacen parecer que uno de los factores importa más que el otro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff32fbaa-7965-42c1-9b73-3640414b77f2",
   "metadata": {},
   "source": [
    "Una de las formas en las que se puede mitigar este problema es penalizando a los parámetros del modelo, cambiando la función de costo:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc78736-9d8e-4e8b-94f3-6647bdaeb0d1",
   "metadata": {},
   "source": [
    "$$ \\text{RSS}_{L2} = \\sum_{i=1}^n e_i^2  + \\lambda \\sum_{j=1}^p \\hat{\\beta_j}^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d942bf5-fb39-44a0-b612-4ec05ab99b71",
   "metadata": {},
   "source": [
    "El *L2* significa que se está agregando una penalización de segundo orden. Lo que hace esta penalización es que los factores ahora sólo tendrán permitido crecer si hay una reducción al menos proporcional en el error (sacrificamos sesgo, pero reducimos la varianza)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c0cafb-c152-48e4-a345-bb5348eb16c7",
   "metadata": {},
   "source": [
    "Asimismo, existe la penalización *L1*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9f2d93-d151-47ed-834f-4a7e91e94286",
   "metadata": {},
   "source": [
    "$$ \\text{RSS}_{L1} = \\sum_{i=1}^n e_i^2  + \\lambda \\sum_{j=1}^p |\\hat{\\beta_j}| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea95f232-25ab-4b4c-99b3-075a18878d95",
   "metadata": {},
   "source": [
    "A las penalizaciones *L2* y *L1* se les conoce también como Ridge y Lasso, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41dfafb-fd1f-475a-a718-dec1e3773326",
   "metadata": {},
   "source": [
    "Para realizar una regresión con penalización de Ridge o de Lasso usamos el objeto `Ridge(alpha=?)` o `Lasso(alpha=?)` en lugar de `LinearRegression()` de `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce36cb41-005e-4cb0-b8ab-92e6ae6c4c19",
   "metadata": {},
   "source": [
    "Utiliza el dataset de publicidad (Advertising.csv) y realiza 3 regresiones múltiples:\n",
    "\n",
    "$$ \\text{sales} = \\beta_0 + \\beta_1 (\\text{TV}) + \\beta_2 (\\text{radio}) + \\beta_3 (\\text{newspaper}) + \\epsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92e4008-ada1-4e82-9756-23fd357821d2",
   "metadata": {},
   "source": [
    "1. Sin penalización\n",
    "2. Con penalización L2\n",
    "3. Con penalización L1\n",
    "\n",
    "Compara los resultados de los parámetros y sus *p-values*, y los $R^2$ resultantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "489b6c52-9025-4ca7-8e96-ca70c294cf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f859166-06cf-478e-89d7-e6e5c2cb5ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>38.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>13.8</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>94.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>177.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>283.6</td>\n",
       "      <td>42.0</td>\n",
       "      <td>66.2</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>232.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0     TV  radio  newspaper  sales\n",
       "0             1  230.1   37.8       69.2   22.1\n",
       "1             2   44.5   39.3       45.1   10.4\n",
       "2             3   17.2   45.9       69.3    9.3\n",
       "3             4  151.5   41.3       58.5   18.5\n",
       "4             5  180.8   10.8       58.4   12.9\n",
       "..          ...    ...    ...        ...    ...\n",
       "195         196   38.2    3.7       13.8    7.6\n",
       "196         197   94.2    4.9        8.1    9.7\n",
       "197         198  177.0    9.3        6.4   12.8\n",
       "198         199  283.6   42.0       66.2   25.5\n",
       "199         200  232.1    8.6        8.7   13.4\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Advertising.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dc54f687-459c-4458-beb0-688593b91110",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = data[\"TV\"].values.reshape(-1,1)\n",
    "x2 = data[\"radio\"].values.reshape(-1,1)\n",
    "x3 = data[\"newspaper\"].values.reshape(-1,1)\n",
    "y = data[\"sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5986d30d-4418-4b26-96cf-20fdddd44ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(y)\n",
    "ones = np.ones([n,1])\n",
    "X = np.hstack([ones,x1,x2,x3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6baa68-4511-44fc-9316-c712be17fba6",
   "metadata": {},
   "source": [
    "## Sin penalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c4f6c6fa-9596-43fc-a7f4-9ad9e915ecbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared:         </th> <td>   0.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   570.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 11 Sep 2025</td> <th>  Prob (F-statistic):</th> <td>1.58e-96</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:41:22</td>     <th>  Log-Likelihood:    </th> <td> -386.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   780.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   196</td>      <th>  BIC:               </th> <td>   793.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    2.9389</td> <td>    0.312</td> <td>    9.422</td> <td> 0.000</td> <td>    2.324</td> <td>    3.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>    0.0458</td> <td>    0.001</td> <td>   32.809</td> <td> 0.000</td> <td>    0.043</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>    0.1885</td> <td>    0.009</td> <td>   21.893</td> <td> 0.000</td> <td>    0.172</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>   -0.0010</td> <td>    0.006</td> <td>   -0.177</td> <td> 0.860</td> <td>   -0.013</td> <td>    0.011</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>60.414</td> <th>  Durbin-Watson:     </th> <td>   2.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 151.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.327</td> <th>  Prob(JB):          </th> <td>1.44e-33</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.332</td> <th>  Cond. No.          </th> <td>    454.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      sales       & \\textbf{  R-squared:         } &     0.897   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.896   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     570.3   \\\\\n",
       "\\textbf{Date:}             & Thu, 11 Sep 2025 & \\textbf{  Prob (F-statistic):} &  1.58e-96   \\\\\n",
       "\\textbf{Time:}             &     10:41:22     & \\textbf{  Log-Likelihood:    } &   -386.18   \\\\\n",
       "\\textbf{No. Observations:} &         200      & \\textbf{  AIC:               } &     780.4   \\\\\n",
       "\\textbf{Df Residuals:}     &         196      & \\textbf{  BIC:               } &     793.6   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &       2.9389  &        0.312     &     9.422  &         0.000        &        2.324    &        3.554     \\\\\n",
       "\\textbf{x1}    &       0.0458  &        0.001     &    32.809  &         0.000        &        0.043    &        0.049     \\\\\n",
       "\\textbf{x2}    &       0.1885  &        0.009     &    21.893  &         0.000        &        0.172    &        0.206     \\\\\n",
       "\\textbf{x3}    &      -0.0010  &        0.006     &    -0.177  &         0.860        &       -0.013    &        0.011     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 60.414 & \\textbf{  Durbin-Watson:     } &    2.084  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.000 & \\textbf{  Jarque-Bera (JB):  } &  151.241  \\\\\n",
       "\\textbf{Skew:}          & -1.327 & \\textbf{  Prob(JB):          } & 1.44e-33  \\\\\n",
       "\\textbf{Kurtosis:}      &  6.332 & \\textbf{  Cond. No.          } &     454.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  sales   R-squared:                       0.897\n",
       "Model:                            OLS   Adj. R-squared:                  0.896\n",
       "Method:                 Least Squares   F-statistic:                     570.3\n",
       "Date:                Thu, 11 Sep 2025   Prob (F-statistic):           1.58e-96\n",
       "Time:                        10:41:22   Log-Likelihood:                -386.18\n",
       "No. Observations:                 200   AIC:                             780.4\n",
       "Df Residuals:                     196   BIC:                             793.6\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          2.9389      0.312      9.422      0.000       2.324       3.554\n",
       "x1             0.0458      0.001     32.809      0.000       0.043       0.049\n",
       "x2             0.1885      0.009     21.893      0.000       0.172       0.206\n",
       "x3            -0.0010      0.006     -0.177      0.860      -0.013       0.011\n",
       "==============================================================================\n",
       "Omnibus:                       60.414   Durbin-Watson:                   2.084\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              151.241\n",
       "Skew:                          -1.327   Prob(JB):                     1.44e-33\n",
       "Kurtosis:                       6.332   Cond. No.                         454.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols = sm.OLS(y, X)\n",
    "results = ols.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7d676598-add1-4793-ad74-6f5a70bf92a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    1.267295e-17\n",
      "x1       1.509960e-81\n",
      "x2       1.505339e-54\n",
      "x3       8.599151e-01\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "p_values = results.pvalues\n",
    "print(p_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b676f-b11d-4919-aeaf-e75a72dc0387",
   "metadata": {},
   "source": [
    "## Con penalización L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cc1dc8b0-007b-4eed-845e-ee354303ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d515c843-0bcf-4be5-8763-04a50d8e77a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Intercept:2.93892841431542\n",
      "Ridge Coeficientes:[ 0.          0.04576464  0.18852756 -0.00103689]\n",
      "Ridge R2:0.8972106381360829\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=0.5)\n",
    "ridge.fit(X, y)\n",
    "r2_ridge= r2_score(y, ridge.predict(X))\n",
    "print(\"Ridge Intercept:\" + str(ridge.intercept_))\n",
    "print(\"Ridge Coeficientes:\" + str(ridge.coef_))\n",
    "print(\"Ridge R2:\" + str(r2_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "329dac7e-accc-49f1-86be-c323fc308999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "556.8252631344158"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(y)\n",
    "p = 4\n",
    "y_pred = ridge.predict(X)\n",
    "residuals = y - y_pred\n",
    "# Suma de cuadrados residual\n",
    "RSS = np.sum(residuals**2)  \n",
    "RSS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "bd7a965f-49d9-4d95-bc0c-a381c0c8ffc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.685510373766222"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSE = np.sqrt(RSS / (n - p))\n",
    "RSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0cc55264-7a60-453d-b63b-199d858e28d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31190824, 0.0013949 , 0.00861123, 0.00587101])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma2 = RSS / (n - p)\n",
    "var_beta = np.linalg.inv(X.T @ X) * sigma2\n",
    "std_beta = np.sqrt(np.diag(var_beta))\n",
    "std_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ae16a15e-f0ed-4503-b986-ce214fc180ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , 32.80862378, 21.89321037, -0.17661247])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estadísticos t\n",
    "t_stats = ridge.coef_ / std_beta\n",
    "t_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "23b72cab-4072-4aa1-8421-b5339ff9f6cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0, 0.0, 0.8599951606746024]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grados de libertad\n",
    "df = n - p\n",
    "\n",
    "# p-values bilaterales\n",
    "p_values = [2 * (1 - stats.t.cdf(np.abs(t), df)) for t in t_stats]\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84145994-21a6-434f-a3b4-1b77305ba5ca",
   "metadata": {},
   "source": [
    "## Con penalización L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23804a46-c07b-4047-88d4-a2de3c96b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8d243f57-e0b7-4773-999f-d0ee90538d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Intercept: 2.980656625064583\n",
      "Lasso Coeficientes: [ 0.          0.04570812  0.18572931 -0.        ]\n",
      "Lasso R2: 0.8971515892246072\n"
     ]
    }
   ],
   "source": [
    "lasso = Lasso(alpha=0.5)\n",
    "lasso.fit(X, y)\n",
    "r2_lasso= r2_score(y, lasso.predict(X))\n",
    "print(\"Lasso Intercept:\", lasso.intercept_)\n",
    "print(\"Lasso Coeficientes:\", lasso.coef_)\n",
    "print(\"Lasso R2:\", r2_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1319a30e-ab63-4ee2-bf65-600ad892620f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "557.1451398714054"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(y)\n",
    "p = 4\n",
    "y_pred = lasso.predict(X)\n",
    "residuals = y - y_pred\n",
    "# Suma de cuadrados residual\n",
    "RSS = np.sum(residuals**2)  \n",
    "RSS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "e980980d-2761-45b9-bd3f-c91bcf1b9baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.685994437784972"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RSE = np.sqrt(RSS / (n - p))\n",
    "RSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "004c463b-dffe-46d1-999a-c0ac1936d44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31199781, 0.0013953 , 0.00861371, 0.0058727 ])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma2 = RSS / (n - p)\n",
    "var_beta = np.linalg.inv(X.T @ X) * sigma2\n",
    "std_beta = np.sqrt(np.diag(var_beta))\n",
    "std_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "c40a8199-c279-4f6c-8309-ecfc5569de53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , 32.75869572, 21.56206482, -0.        ])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estadísticos t\n",
    "t_stats = lasso.coef_ / std_beta\n",
    "t_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "3b0143cd-2555-485e-808a-4b17064b3fa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grados de libertad\n",
    "df = n - p\n",
    "\n",
    "# p-values bilaterales\n",
    "p_values = [2 * (1 - stats.t.cdf(np.abs(t), df)) for t in t_stats]\n",
    "p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fa374f-db67-45b2-8ac1-acfe0156c106",
   "metadata": {},
   "source": [
    "## Comparación de parámetros, p-values y R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4006988b-abc7-4d33-ae84-0d1916140821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            OLS_coef      OLS_pval  Ridge_coef  Ridge_pval  Lasso_coef  \\\n",
      "Intercepto  2.938889  1.267295e-17    2.938928         1.0    2.980657   \n",
      "TV          0.045765  1.509960e-81    0.045765         0.0    0.045708   \n",
      "Radio       0.188530  1.505339e-54    0.188528         0.0    0.185729   \n",
      "Newspaper  -0.001037  8.599151e-01   -0.001037         1.0   -0.000000   \n",
      "\n",
      "            Lasso_pval  \n",
      "Intercepto         1.0  \n",
      "TV                 0.0  \n",
      "Radio              0.0  \n",
      "Newspaper          1.0  \n",
      "R2 sin penalización: 0.897 R2 Ridge: 0.897 R2 Lasso: 0.897\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Resultados OLS\n",
    "ols_params = results.params.values        \n",
    "ols_pvalues = results.pvalues.values\n",
    "ols_r2 = results.rsquared\n",
    "\n",
    "# Resultados Ridge\n",
    "ridge_params = [ridge.intercept_] + list(ridge.coef_[1:])  # quitamos el coef de la constante extra\n",
    "ridge_pvalues = p_values[:4] \n",
    "ridge_r2 = r2_ridge\n",
    "\n",
    "# Resultados Lasso\n",
    "lasso_params = [lasso.intercept_] + list(lasso.coef_[1:])\n",
    "lasso_pvalues = p_values[:4]\n",
    "lasso_r2 = r2_lasso\n",
    "\n",
    "# Tabla comparativa\n",
    "df_comp = pd.DataFrame({\n",
    "    \"OLS_coef\": ols_params,\n",
    "    \"OLS_pval\": ols_pvalues,\n",
    "    \"Ridge_coef\": ridge_params,\n",
    "    \"Ridge_pval\": ridge_pvalues,\n",
    "    \"Lasso_coef\": lasso_params,\n",
    "    \"Lasso_pval\": lasso_pvalues\n",
    "}, index=[\"Intercepto\", \"TV\", \"Radio\", \"Newspaper\"])\n",
    "\n",
    "print(df_comp)\n",
    "\n",
    "print(\"R2 sin penalización:\", round(ols_r2,3),\n",
    "      \"R2 Ridge:\", round(ridge_r2,3),\n",
    "      \"R2 Lasso:\", round(r2_lasso,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8acfa61-5c04-447a-9c8a-4a788e01581d",
   "metadata": {},
   "source": [
    "- Parámetros: Ridge tiende a encoger coeficientes pero no los elimina, por eso Newspaper sigue con valor casi igual a sin penalización. Newspaper se volvió exactamente 0 porque Lasso \"seleccionó variables\" y eliminó Newspaper del modelo.\n",
    "- P-values: Debo tener un error porque si en Lasso ya no está Newspaper, por qué su p-value sería 1?\n",
    "-  R2: Igual en los 3 casos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
